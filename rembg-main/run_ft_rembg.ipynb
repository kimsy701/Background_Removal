{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SupT1kGUIPoU3KY2WHj78kpXGKi8Qnwp","timestamp":1696509791856}],"gpuType":"T4","mount_file_id":"1byR6kVMcRWn5QOeOh6LRWPE0qiCFdfAt","authorship_tag":"ABX9TyPo49DhqDcQ3MerSIV8qhvf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0GRc0Rk9pExA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697544304903,"user_tz":-540,"elapsed":9800,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"febb222e-c5d6-46ce-c515-6469d89eb54e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#when using google colab, run this code\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\"\"\""]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/rembg-main')"],"metadata":{"id":"7evIhaFYpFfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import torchvision\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch.optim as optim\n","import torchvision.transforms as standard_transforms\n","\n","import numpy as np\n","import glob\n","import os\n","import gdown\n","os.chdir('/content/drive/MyDrive/U-2-Net-master')\n","from data_loader import Rescale\n","from data_loader import RescaleT\n","from data_loader import RandomCrop\n","from data_loader import ToTensor\n","from data_loader import ToTensorLab\n","from data_loader import SalObjDataset\n","\n","from model import U2NET\n","from model import U2NETP\n"],"metadata":{"id":"k1bWOv4HlRbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/rembg-main')"],"metadata":{"id":"WDTy9xhPmtQ_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["0. convert pth model to onnx"],"metadata":{"id":"GzH4TBrNlASN"}},{"cell_type":"code","source":["#run this code in ipynb cell, or run this code in cmd(in cmd, without \"!\")\n","#!pip install onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLcVT7SXk_im","executionInfo":{"status":"ok","timestamp":1697544342478,"user_tz":-540,"elapsed":8896,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"fa959148-9833-4d01-a928-ba02d4602c4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/14.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/14.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/14.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m11.6/14.6 MB\u001b[0m \u001b[31m181.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.14.1\n"]}]},{"cell_type":"code","source":["import torch.onnx\n","import onnx\n","\n","#Function to Convert model from PTH file to ONNX file\n","def Convert_ONNX(batch_size):\n","\n","    # set the model to inference mode : (batch norm, dropout, 이동 평균 변경 방지)\n","    model.eval()\n","\n","    dummy_input =  torch.randn(batch_size, 3,512, 512, requires_grad=True)\n","\n","    # Export the model\n","    torch.onnx.export(model,         # model being run\n","         dummy_input,       # model input (or a tuple for multiple inputs)\n","         \"./rembg/sessions/u2net_bce_itr_370000_train_0.263291_tar_0.018606.onnx\",  # where to save the onnx model\n","         export_params=True,  # store the trained parameter weights inside the model file\n","         opset_version=10,    # the ONNX version to export the model to\n","         do_constant_folding=True,  # whether to execute constant folding for optimization\n","         input_names = ['modelInput'],   # the model's input names\n","         output_names = ['modelOutput'], # the model's output names\n","         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes\n","                                'modelOutput' : {0 : 'batch_size'}})\n","    print(\" \")\n","    print('Model has been converted to ONNX')"],"metadata":{"id":"o1DtiSA96a-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = U2NET(3, 1)\n","\n","batch_size=4 #기존 12이지만 램부족으로 모델 변경시 batch size 축소함\n","path = \"./rembg/sessions/u2net_bce_itr_370000_train_0.263291_tar_0.018606.pth\" #pth 파일\n","model.load_state_dict(torch.load(path))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viGgZ-x7kAEY","executionInfo":{"status":"ok","timestamp":1697544395657,"user_tz":-540,"elapsed":11615,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"89b54c0b-535f-4c96-96d4-f6744ac53432"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["Convert_ONNX(batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRbWKpqskAvp","executionInfo":{"status":"ok","timestamp":1697544441526,"user_tz":-540,"elapsed":32570,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"e06fbba5-d2bc-4f97-93cc-3595513738aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n","/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_helper.py:829: UserWarning: You are trying to export the model with onnx:Resize for ONNX opset version 10. This operator might cause results to not match the expected results by PyTorch.\n","ONNX's Upsample/Resize operator did not match Pytorch's Interpolation until opset 11. Attributes to determine how to transform the input were added in onnx:Resize in opset 11 to support Pytorch's behavior (like coordinate_transformation_mode and nearest_mode).\n","We recommend using opset 11 and above for models using this operator.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n"," \n","Model has been converted to ONNX\n"]}]},{"cell_type":"markdown","source":["1. Test finetuning model"],"metadata":{"id":"ocsRgmpn1QJ7"}},{"cell_type":"code","source":["#test finetuning model\n","\n","#run this code in ipynb cell, or run this code in cmd(in cmd, without \"!\")\n","#!pip install pymatting\n","#!pip install onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_T3D3PVmzD44","executionInfo":{"status":"ok","timestamp":1697544472660,"user_tz":-540,"elapsed":11255,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"0a1da581-d962-4351-96bb-324238c42b00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pymatting\n","  Downloading PyMatting-1.1.10-py3-none-any.whl (52 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymatting) (1.23.5)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from pymatting) (9.4.0)\n","Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting) (0.56.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pymatting) (1.11.3)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting) (67.7.2)\n","Installing collected packages: pymatting\n","Successfully installed pymatting-1.1.10\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.1\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/rembg-main') #rembg_main 모델 경로\n","\n","from rembg.sessions.u2net_custom import U2netCustomSession\n","#from rembg import remove, new_session\n","\n","from rembg.bg import remove\n","import cv2"],"metadata":{"id":"JiSmDIbL4rFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Any, List, Optional, Tuple, Union\n","from PIL import Image, ImageOps\n","from PIL.Image import Image as PILImage\n","from rembg.session_factory import new_session\n","from rembg.sessions.base import BaseSession\n","from enum import Enum\n","import numpy as np\n","\n","\n","class ReturnType(Enum):\n","    BYTES = 0\n","    PILLOW = 1\n","    NDARRAY = 2\n","\n","def alpha_matting_cutout(\n","    img: PILImage,\n","    mask: PILImage,\n","    foreground_threshold: int,\n","    background_threshold: int,\n","    erode_structure_size: int,\n",") -> PILImage:\n","    \"\"\"\n","    Perform alpha matting on an image using a given mask and threshold values.\n","\n","    This function takes a PIL image `img` and a PIL image `mask` as input, along with\n","    the `foreground_threshold` and `background_threshold` values used to determine\n","    foreground and background pixels. The `erode_structure_size` parameter specifies\n","    the size of the erosion structure to be applied to the mask.\n","\n","    The function returns a PIL image representing the cutout of the foreground object\n","    from the original image.\n","    \"\"\"\n","    if img.mode == \"RGBA\" or img.mode == \"CMYK\":\n","        img = img.convert(\"RGB\")\n","\n","    img = np.asarray(img)\n","    mask = np.asarray(mask)\n","\n","    is_foreground = mask > foreground_threshold\n","    is_background = mask < background_threshold\n","\n","    structure = None\n","    if erode_structure_size > 0:\n","        structure = np.ones(\n","            (erode_structure_size, erode_structure_size), dtype=np.uint8\n","        )\n","\n","    is_foreground = binary_erosion(is_foreground, structure=structure)\n","    is_background = binary_erosion(is_background, structure=structure, border_value=1)\n","\n","    trimap = np.full(mask.shape, dtype=np.uint8, fill_value=128)\n","    trimap[is_foreground] = 255\n","    trimap[is_background] = 0\n","\n","    img_normalized = img / 255.0\n","    trimap_normalized = trimap / 255.0\n","\n","    alpha = estimate_alpha_cf(img_normalized, trimap_normalized)\n","    foreground = estimate_foreground_ml(img_normalized, alpha)\n","    cutout = stack_images(foreground, alpha)\n","\n","    cutout = np.clip(cutout * 255, 0, 255).astype(np.uint8)\n","    cutout = Image.fromarray(cutout)\n","\n","    return cutout\n","\n","def naive_cutout(img: PILImage, mask: PILImage) -> PILImage:\n","    empty = Image.new(\"RGBA\", (img.size), 0)\n","    cutout = Image.composite(img, empty, mask)\n","    return cutout\n","\n","def putalpha_cutout(img: PILImage, mask: PILImage) -> PILImage:\n","    img.putalpha(mask)\n","    return img\n","\n","\n","def get_concat_v_multi(imgs: List[PILImage]) -> PILImage:\n","    pivot = imgs.pop(0)\n","    for im in imgs:\n","        pivot = get_concat_v(pivot, im)\n","    return pivot\n","\n","\n","def get_concat_v(img1: PILImage, img2: PILImage) -> PILImage:\n","    dst = Image.new(\"RGBA\", (img1.width, img1.height + img2.height))\n","    dst.paste(img1, (0, 0))\n","    dst.paste(img2, (0, img1.height))\n","    return dst\n","\n","def remove_hy(\n","    data: Union[bytes, PILImage, np.ndarray],\n","    alpha_matting: bool = False,\n","    alpha_matting_foreground_threshold: int = 240,\n","    alpha_matting_background_threshold: int = 10,\n","    alpha_matting_erode_size: int = 10,\n","    session: Optional[BaseSession] = None,\n","    only_mask: bool = False,\n","    post_process_mask: bool = False,\n","    bgcolor: Optional[Tuple[int, int, int, int]] = None,\n","    *args: Optional[Any],\n","    **kwargs: Optional[Any]\n",")-> Union[bytes, Image.Image, np.ndarray]:\n","\n","    if isinstance(data, PILImage):\n","        return_type = ReturnType.PILLOW\n","        img = data\n","    elif isinstance(data, bytes):\n","        return_type = ReturnType.BYTES\n","        #img = Image.open(io.BytesIO(data))\n","        img=data\n","    elif isinstance(data, Image.Image):\n","            return_type = ReturnType.PILLOW\n","    elif isinstance(data, np.ndarray):\n","        return_type = ReturnType.NDARRAY\n","        img = Image.fromarray(data)  #array to PIL image\n","        #img=data #hy\n","    else:\n","        raise ValueError(\"Input type {} is not supported.\".format(type(data)))\n","\n","    putalpha = kwargs.pop(\"putalpha\", False)\n","\n","\n","    # Fix image orientation\n","    #img = fix_image_orientation(img)\n","\n","\n","    if session is None:\n","        #session = new_session(\"u2net\", *args, **kwargs)\n","        session = new_session(\"u2net_custom\", *args, **kwargs) #세션 생성\n","\n","\n","    #img=Image.fromarray(img)\n","\n","\n","    masks = session.predict(img, *args, **kwargs)\n","    cutouts = []\n","\n","    for mask in masks:\n","        if post_process_mask:\n","            mask = Image.fromarray(post_process(np.array(mask)))\n","\n","        if only_mask:\n","            cutout = mask\n","\n","        elif alpha_matting:\n","            try:\n","                cutout = alpha_matting_cutout(\n","                    img,\n","                    mask,\n","                    alpha_matting_foreground_threshold,\n","                    alpha_matting_background_threshold,\n","                    alpha_matting_erode_size,\n","                )\n","            except ValueError:\n","                if putalpha:\n","                    cutout = putalpha_cutout(img, mask)\n","                else:\n","                    cutout = naive_cutout(img, mask)\n","        else:\n","            if putalpha:\n","                cutout = putalpha_cutout(img, mask)\n","            else:\n","                cutout = naive_cutout(img, mask)\n","\n","        cutouts.append(cutout)\n","\n","    cutout = img\n","    if len(cutouts) > 0:\n","        cutout = get_concat_v_multi(cutouts)\n","\n","    if bgcolor is not None and not only_mask:\n","        cutout = apply_background_color(cutout, bgcolor)\n","\n","    if ReturnType.PILLOW == return_type:\n","        return cutout\n","\n","    if ReturnType.NDARRAY == return_type:\n","        return np.asarray(cutout)\n","\n","    bio = io.BytesIO()\n","    cutout.save(bio, \"PNG\")\n","    bio.seek(0)\n","\n","    return bio.read()"],"metadata":{"id":"uTAgUUgZBz0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define model path\n","modelpath= \"/content/drive/MyDrive/rembg-main/rembg/sessions/u2net_bce_itr_370000_train_0.263291_tar_0.018606.onnx\" #put finetuned model path"],"metadata":{"id":"Fa_XmYBJlMQ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Processing images in input folder, without alpha matting\n","\"\"\"\n","import onnxruntime as ort\n","import io\n","from pathlib import Path\n","\n","#create custom session\n","model_path = modelpath\n","sess_opts = ort.SessionOptions()\n","custom_session = U2netCustomSession(\"temp_u2net_custom\", sess_opts, model_path=model_path)\n","\n","for file in Path('/content/drive/MyDrive/rembg-main/ft_test_input').glob('*.png'):\n","    input_path = str(file)\n","    output_path = str('/content/drive/MyDrive/rembg-main/ft_test_output/' + file.name)  # Use the name of the input file for the output\n","\n","    with open(input_path, 'rb') as i:\n","        with open(output_path, 'wb') as o:\n","            input = i.read()\n","            # Convert the input data (bytes) to a PIL Image object\n","            input = Image.open(io.BytesIO(input))\n","\n","            output = remove_hy(input, session=custom_session)\n","            by = io.BytesIO()\n","            output.save(by, format='png')\n","            o.write(by.getvalue()) # Write the processed image data to the output file\n","            \"\"\""],"metadata":{"id":"6A3OSOhljivf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Processing images in input folder, this time, using alpha matting\n","import onnxruntime as ort\n","import io\n","from pathlib import Path\n","import io\n","from enum import Enum\n","from typing import Any, List, Optional, Tuple, Union\n","\n","import numpy as np\n","from cv2 import (\n","    BORDER_DEFAULT,\n","    MORPH_ELLIPSE,\n","    MORPH_OPEN,\n","    GaussianBlur,\n","    getStructuringElement,\n","    morphologyEx,\n",")\n","from PIL import Image, ImageOps\n","from PIL.Image import Image as PILImage\n","from pymatting.alpha.estimate_alpha_cf import estimate_alpha_cf\n","from pymatting.foreground.estimate_foreground_ml import estimate_foreground_ml\n","from pymatting.util.util import stack_images\n","from scipy.ndimage import binary_erosion\n","\n","\n","#create custom session\n","model_path = modelpath\n","sess_opts = ort.SessionOptions()\n","custom_session = U2netCustomSession(\"temp_u2net_custom\", sess_opts, model_path=model_path)\n","\n","for file in Path('/content/drive/MyDrive/rembg-main/ft_test_input').glob('*.png'):\n","    input_path = str(file)\n","    output_path = str('/content/drive/MyDrive/rembg-main/ft_test_output_alpha/' + file.name)  # Use the name of the input file for the output\n","\n","    with open(input_path, 'rb') as i:\n","        with open(output_path, 'wb') as o:\n","            input = i.read()\n","            # Convert the input data (bytes) to a PIL Image object\n","            input = Image.open(io.BytesIO(input))\n","\n","            output = remove_hy(input, session=custom_session,alpha_matting=True )\n","            by = io.BytesIO()\n","            output.save(by, format='png')\n","            o.write(by.getvalue()) # Write the processed image data to the output file"],"metadata":{"id":"s-W39so0mku7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697546603677,"user_tz":-540,"elapsed":376243,"user":{"displayName":"김혜연","userId":"14076391861970698514"}},"outputId":"832fbadd-f06b-4413-eec1-86b9cf3f35ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n","PERFORMANCE WARNING:\n","Thresholded incomplete Cholesky decomposition failed due to insufficient positive-definiteness of matrix A with parameters:\n","    discard_threshold = 1.000000e-04\n","    shift = 0.000000e+00\n","Try decreasing discard_threshold or start with a larger shift\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FXmVWRcZ8hV8"},"execution_count":null,"outputs":[]}]}